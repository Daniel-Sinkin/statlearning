{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "It is well-known that ridge regression tends to give similar coefficient values to correlated variables, whereas the lasso may give quite different coefficient values to correlated variables. We will now explore this property in a very simple setting.\n",
    "\n",
    "Suppose that $n = 2, p = 2, x_{11} = x­_{12}, x­_{21} = x_{22}$. Furthermore, suppose that $y_1 + y_2 = 0$ and $x_{11} + x_{21} = 0$ and $x_{12} + x_{22} = 0$, so that the estimate for the intercept in a least squares, ridge regression, or lasso model is zero: $\\hat{\\beta}_0 = 0$.\n",
    "1. Write out the ridge regression optimization problem in this setting.\n",
    "2. Argue that in this setting, the ridge coefficient estimates satisfy $\\beta_1 = \\beta_2$.\n",
    "3. Write out the lasso optimization problem in this setting\n",
    "4. Argue that in this setting, the lasso coefficients $\\beta_1$ and $\\beta_2$ are not unique—in other words, there are many possible solutions to the optimization problem in (3). Describe these solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
