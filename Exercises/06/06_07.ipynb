{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "We will now derive the Bayesian connection to the lasso and ridge regression discussed in Section `6.2.2`.\n",
    "1. Suppose that $y_i = \\beta_0 + \\sum_{j = 1}^p x_{ij}\\beta_j + \\varepsilon_i$ where $\\varepsilon_1, \\dots, \\varepsilon_n$ are independent and identically distributed from a $\\mathcal{N}(0, \\sigma^2)$ distribution. Write out the likelihood for the data.\n",
    "2. Assume the following prior for $\\beta: \\beta_1, \\dots, \\beta_p$ are independent and identically distributed according to a double-exponential distribution with mean $0$ and common scale parameter $b$: i.e. $p(\\beta) = \\frac{1}{2b} \\exp(âˆ’ |\\beta| /b). Write out the posterior for \\beta in this setting.\n",
    "3. Argue that the lasso estimate is the mode for $\\beta$ under this posterior distribution.\n",
    "4. Now assume the following prior for $\\beta: \\beta_1, \\dots ,\\beta_p$ are independent and identically distributed according to a normal distribution with mean zero and variance $c$. Write out the posterior for $\\beta$ in this setting.\n",
    "5. Argue that the ridge regression estimate is both the mode and the mean for $\\beta$ under this posterior distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
